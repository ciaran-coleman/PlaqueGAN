{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c1f428",
   "metadata": {},
   "source": [
    "Notebook to sample images from PlaqueGAN and filter using Plaquebox CNN as selection classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d0570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.utils as vutils\n",
    "import torchvision\n",
    "from torch.cuda import amp\n",
    "import numpy as np\n",
    "\n",
    "from operation import load_params, get_config\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models import Generator\n",
    "\n",
    "from models_orig import Generator as GeneratorOld\n",
    "from metrics.metric_utils import Batched_Normalize\n",
    "import os\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255edd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.parallel.data_parallel.DataParallel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# backbone of the CNN model to load the model parameters into\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, fc_nodes=512, num_classes=3, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# load plaquebox model\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "pbox_ckpt_path = '../Plaquebox/plaquebox-paper-master/models/CNN_model_parameters.pkl'\n",
    "norm_stats_path = '../Plaquebox/plaquebox-paper-master/utils/normalization.npy'\n",
    "norm = np.load(norm_stats_path, allow_pickle=True).item()\n",
    "pbox_cnn = torch.load(pbox_ckpt_path, map_location=lambda storage, loc: storage)\n",
    "pbox_cnn = list(pbox_cnn.modules())[1]\n",
    "# pbox_cnn.to(device)\n",
    "# _=pbox_cnn.eval()\n",
    "\n",
    "norm_stats_path = '../Plaquebox/plaquebox-paper-master/utils/normalization.npy'\n",
    "norm = np.load(norm_stats_path, allow_pickle=True).item()\n",
    "# trans_cnn = transforms.Compose([transforms.ToTensor(),\n",
    "#                             transforms.Normalize(mean=norm['mean'],std=norm['std'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9054b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def truncated_z_sample(batch_size, z_dim, truncation = 0.5, seed = None):\n",
    "    state = None if seed is None else np.random.RandomState(seed)\n",
    "    if truncation > 0:\n",
    "        values = truncnorm.rvs(-2, 2, size=(batch_size, z_dim), random_state=state)\n",
    "        return torch.as_tensor(truncation * values, dtype=torch.float32)\n",
    "    else:\n",
    "        return torch.randn((batch_size, z_dim))\n",
    "\n",
    "def sample_generator(netG, z, norm_stats=None):\n",
    "    # with amp.autocast():\n",
    "    imgs = netG(z)[0]\n",
    "    # convert images from -1 1 to 0 255 uint8 (as would be done if saving)\n",
    "    imgs_convert = (imgs * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    # convert back to torch FloatTensor\n",
    "    imgs_convert = imgs_convert.to(torch.float32).div_(255)\n",
    "    # normalize\n",
    "    if norm_stats is not None:\n",
    "        imgs_convert = Batched_Normalize(imgs_convert, norm_stats['mean'], norm_stats['std'])\n",
    "    return imgs.add(1).mul(0.5).to('cpu'), imgs_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd18facd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def sample_gan_class_confidence(args_dict, classifier, norm, save_dir = '../Plaquebox/plaquebox-paper-master/data/tiles/train_and_val'):\n",
    "    \n",
    "    all_classes = [0,1,2]\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    base_dir = args_dict['base_dir']\n",
    "    # acceptance threshold for desired class(es)\n",
    "    thresh_true_class = args_dict['thresh_true_class']\n",
    "    # rejection threshold for remaining classes - do not want these with too high confidence (but some confidence may be useful)\n",
    "    thresh_false_class = args_dict['thresh_false_class']\n",
    "    batch_class = args_dict['batch_class']\n",
    "    batch_gen = args_dict['batch_gen']\n",
    "    ema = args_dict['ema']\n",
    "    \n",
    "    labels_stacked = []\n",
    "    file_paths = []\n",
    "    total_saved = 0\n",
    "    for morph, ckpt_iter, target_gen, class_idx in zip(args_dict['morph'], args_dict['ckpts_use'], args_dict['target_gen'], args_dict['class_idx']):\n",
    "        \n",
    "        label = [1 if i in class_idx else 0 for i in range(3)]\n",
    "        not_class_idx = [i for i in all_classes if i not in class_idx]\n",
    "#         ckpt_path = os.path.join(args_dict['base_dir'], f'{morph}', 'models', f'all_{ckpt_iter}.pth')\n",
    "        ckpt_path = os.path.join(args_dict['base_dir'], f'{morph}_final', 'models', f'all_{ckpt_iter}.pth')\n",
    "        \n",
    "        checkpoint= torch.load(ckpt_path)\n",
    "        \n",
    "        # load in the generator\n",
    "        with open(os.path.join(base_dir, f'{morph}_final', 'args.txt'), mode='r') as f:\n",
    "            args_train = json.load(f)\n",
    "            model_config = args_train['model_config']\n",
    "            model_config = get_config('model_configs.csv', model_config, type='model')\n",
    "            noise_dim = model_config['nz']\n",
    "\n",
    "            netG = Generator(\n",
    "                    nz                  = model_config['nz'],\n",
    "                    activation          = model_config['g_activation'],\n",
    "                    chan_attn           = model_config['g_chan_attn'],\n",
    "                    sle_map             = model_config['g_skip_map'],\n",
    "                    skip_conn           = model_config['g_skip_conn'],\n",
    "                    spatial_attn        = model_config['g_spatial_attn'],\n",
    "                    attn_layers         = model_config['g_attn_layers'],\n",
    "                    conv_layers         = model_config['g_conv_layers'],\n",
    "                    alternate_layers    = model_config['g_alternate_layers'],\n",
    "                    anti_alias          = model_config['g_anti_alias'],\n",
    "                    noise_inj           = model_config['g_noise_inj'],\n",
    "                    multi_res_out       = model_config['g_multi_res_out'],\n",
    "                    small_im_size       = model_config['g_small_im_size'],\n",
    "                    use_tanh            = model_config['use_tanh']\n",
    "            )\n",
    "\n",
    "            print('all ok!')   \n",
    "        \n",
    "        # load in parameters\n",
    "        if ema:\n",
    "            load_params(netG, checkpoint['g_ema'])\n",
    "        else:\n",
    "            load_params(netG, checkpoint['g'])\n",
    "        \n",
    "        netG.to(device)\n",
    "        classifier.to(device)\n",
    "        classifier.eval()\n",
    "        \n",
    "        # generator warm-up\n",
    "        for i in range(100):\n",
    "            z = truncated_z_sample(batch_gen, noise_dim, truncation=0).to(device)\n",
    "            _,_ = sample_generator(netG, z, norm_stats=norm)\n",
    "        \n",
    "        generated = 0\n",
    "        while generated < target_gen:\n",
    "\n",
    "            images_2_save = []\n",
    "            images = []\n",
    "            for i in range(batch_class // batch_gen):\n",
    "                z = truncated_z_sample(batch_gen, noise_dim, truncation=0).to(device)\n",
    "                imgs_save, imgs = sample_generator(netG, z, norm_stats=norm)\n",
    "                images_2_save.append(imgs_save)\n",
    "                images.append(imgs)\n",
    "\n",
    "            images = torch.cat(images)\n",
    "            images_2_save = torch.cat(images_2_save)\n",
    "            if images.shape[1] == 1:\n",
    "                images = images.repeat([1,3,1,1])\n",
    "            \n",
    "            # run through classifier\n",
    "            with amp.autocast():\n",
    "                preds = torch.sigmoid(classifier(images)).detach().cpu()\n",
    "\n",
    "            predictions_accept = preds[:, class_idx] > thresh_true_class\n",
    "            idx_accept = torch.all(predictions_accept, dim=1).nonzero()\n",
    "            predictions_accept = preds[idx_accept, not_class_idx] < thresh_false_class\n",
    "            idx_accept = idx_accept[torch.all(predictions_accept, dim=1).nonzero().squeeze()].squeeze()\n",
    "            \n",
    "            #now save the images that pass the threshold requirements\n",
    "            for j in idx_accept:\n",
    "                imarr = images_2_save[j].mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "                pil_img = Image.fromarray(imarr)\n",
    "                pil_img.save(os.path.join(save_dir, 'gan',f'{total_saved}.jpg'), quality=95)\n",
    "                labels_stacked.append(label)\n",
    "                file_paths.append(f'gan/{total_saved}.jpg')\n",
    "                generated +=1\n",
    "                if generated%1000==0:\n",
    "                    print(f'number of {morph} generated: {generated}')\n",
    "                total_saved+=1\n",
    "                if generated==target_gen:\n",
    "                    break\n",
    "            \n",
    "    return file_paths, labels_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca6a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'D:/ucl_masters_data/project/fastGAN_experiments/extended'\n",
    "morphs = ['cored','CAA','cored-diffuse','CAA-diffuse']\n",
    "class_idx = [[0], [2], [0,1], [1,2]]\n",
    "ckpts_use = [90000, 100000, 80000, 70000]\n",
    "target_gen = [35728, 38955, 11198, 7644]\n",
    "\n",
    "thresh_true_class = 0.7 # threshold to accept classes\n",
    "thresh_false_class = 0.3 # threshold to reject other classes\n",
    "args_dict = {'base_dir': base_dir, 'morph': morphs, 'ckpts_use': ckpts_use, 'target_gen': target_gen, \n",
    "             'class_idx': class_idx, 'batch_class': 32, 'batch_gen': 8, 'thresh_true_class': thresh_true_class, \n",
    "             'thresh_false_class': thresh_false_class, 'ema': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17524acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ok!\n",
      "number of cored generated: 1000\n",
      "number of cored generated: 2000\n",
      "number of cored generated: 3000\n",
      "number of cored generated: 4000\n",
      "number of cored generated: 5000\n",
      "number of cored generated: 6000\n",
      "number of cored generated: 7000\n",
      "number of cored generated: 8000\n",
      "number of cored generated: 9000\n",
      "number of cored generated: 10000\n",
      "number of cored generated: 11000\n",
      "number of cored generated: 12000\n",
      "number of cored generated: 13000\n",
      "number of cored generated: 14000\n",
      "number of cored generated: 15000\n",
      "number of cored generated: 16000\n",
      "number of cored generated: 17000\n",
      "number of cored generated: 18000\n",
      "number of cored generated: 19000\n",
      "number of cored generated: 20000\n",
      "number of cored generated: 21000\n",
      "number of cored generated: 22000\n",
      "number of cored generated: 23000\n",
      "number of cored generated: 24000\n",
      "number of cored generated: 25000\n",
      "number of cored generated: 26000\n",
      "number of cored generated: 27000\n",
      "number of cored generated: 28000\n",
      "number of cored generated: 29000\n",
      "number of cored generated: 30000\n",
      "number of cored generated: 31000\n",
      "number of cored generated: 32000\n",
      "number of cored generated: 33000\n",
      "number of cored generated: 34000\n",
      "number of cored generated: 35000\n",
      "all ok!\n",
      "number of CAA generated: 1000\n",
      "number of CAA generated: 2000\n",
      "number of CAA generated: 3000\n",
      "number of CAA generated: 4000\n",
      "number of CAA generated: 5000\n",
      "number of CAA generated: 6000\n",
      "number of CAA generated: 7000\n",
      "number of CAA generated: 8000\n",
      "number of CAA generated: 9000\n",
      "number of CAA generated: 10000\n",
      "number of CAA generated: 11000\n",
      "number of CAA generated: 12000\n",
      "number of CAA generated: 13000\n",
      "number of CAA generated: 14000\n",
      "number of CAA generated: 15000\n",
      "number of CAA generated: 16000\n",
      "number of CAA generated: 17000\n",
      "number of CAA generated: 18000\n",
      "number of CAA generated: 19000\n",
      "number of CAA generated: 20000\n",
      "number of CAA generated: 21000\n",
      "number of CAA generated: 22000\n",
      "number of CAA generated: 23000\n",
      "number of CAA generated: 24000\n",
      "number of CAA generated: 25000\n",
      "number of CAA generated: 26000\n",
      "number of CAA generated: 27000\n",
      "number of CAA generated: 28000\n",
      "number of CAA generated: 29000\n",
      "number of CAA generated: 30000\n",
      "number of CAA generated: 31000\n",
      "number of CAA generated: 32000\n",
      "number of CAA generated: 33000\n",
      "number of CAA generated: 34000\n",
      "number of CAA generated: 35000\n",
      "number of CAA generated: 36000\n",
      "number of CAA generated: 37000\n",
      "number of CAA generated: 38000\n",
      "all ok!\n",
      "number of cored-diffuse generated: 1000\n",
      "number of cored-diffuse generated: 2000\n",
      "number of cored-diffuse generated: 3000\n",
      "number of cored-diffuse generated: 4000\n",
      "number of cored-diffuse generated: 5000\n",
      "number of cored-diffuse generated: 6000\n",
      "number of cored-diffuse generated: 7000\n",
      "number of cored-diffuse generated: 8000\n",
      "number of cored-diffuse generated: 9000\n",
      "number of cored-diffuse generated: 10000\n",
      "number of cored-diffuse generated: 11000\n",
      "all ok!\n",
      "number of CAA-diffuse generated: 1000\n",
      "number of CAA-diffuse generated: 2000\n",
      "number of CAA-diffuse generated: 3000\n",
      "number of CAA-diffuse generated: 4000\n",
      "number of CAA-diffuse generated: 5000\n",
      "number of CAA-diffuse generated: 6000\n",
      "number of CAA-diffuse generated: 7000\n"
     ]
    }
   ],
   "source": [
    "file_paths, labels_stacked = sample_gan_class_confidence(args_dict, pbox_cnn, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9176c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6770e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciara\\anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "labels_stacked = []\n",
    "file_paths = []\n",
    "total_saved = 0\n",
    "for morph, target_gen, class_idx in zip(args_dict['morph'], args_dict['target_gen'], args_dict['class_idx']):\n",
    "    label = [1 if i in class_idx else 0 for i in range(3)]\n",
    "    \n",
    "    generated = 0\n",
    "    while generated < target_gen:\n",
    "        labels_stacked.append(label)\n",
    "        file_paths.append(f'gan/{total_saved}.jpg')\n",
    "        generated +=1\n",
    "        total_saved += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca810a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(data=file_paths,columns=['imagename'])\n",
    "df_out[['cored','diffuse','CAA']] = labels_stacked\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('./train_gann_up_3.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
